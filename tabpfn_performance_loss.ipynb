{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[KeOps] Warning : Cuda libraries were not detected on the system or could not be loaded ; using cpu only mode\n"
     ]
    }
   ],
   "source": [
    "# stdlib\n",
    "from typing import Any, List\n",
    "\n",
    "# third party\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# synthcity absolute\n",
    "from synthcity.plugins.core.dataloader import DataLoader, GenericDataLoader\n",
    "from synthcity.plugins.core.distribution import Distribution\n",
    "from synthcity.plugins.core.plugin import Plugin\n",
    "from synthcity.plugins.core.schema import Schema\n",
    "from synthcity.plugins.core.distribution import (\n",
    "    Distribution,\n",
    "    IntegerDistribution,\n",
    ")\n",
    "from tabpfn import TabPFNClassifier\n",
    "import torch\n",
    "from tqdm import tqdm\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from ForestDiffusion import ForestDiffusionModel\n",
    "from synthcity.plugins import Plugins\n",
    "from smote import MySMOTE\n",
    "from imblearn.over_sampling import SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class tabpfn_points_plugin(Plugin):\n",
    "    \"\"\"TabPFN integration in synthcity.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        n_random_test_samples: int = 3_000,\n",
    "        device: str = \"cuda:0\",\n",
    "        n_batches: int = 200,\n",
    "        lr: float = 0.1,\n",
    "        n_permutations: int = 3,\n",
    "        n_ensembles: int = 3,\n",
    "        store_intermediate_data: bool = False,\n",
    "        n_test_from_false_train: int = 0,\n",
    "        n_random_features_to_add: int = 1,\n",
    "        random_test_points_scale: float = 2,\n",
    "        init_scale_factor: float = 5,\n",
    "        **kwargs: Any\n",
    "    ) -> None:\n",
    "        super().__init__(**kwargs)\n",
    "        self.n_random_test_samples = n_random_test_samples\n",
    "        self.device = device\n",
    "        self.n_batches = n_batches\n",
    "        self.lr = lr\n",
    "        self.n_permutations = n_permutations\n",
    "        self.n_ensembles = n_ensembles\n",
    "        self.preprocessor = StandardScaler()\n",
    "        self.store_intermediate_data = store_intermediate_data\n",
    "        self.n_test_from_false_train = n_test_from_false_train\n",
    "        self.n_random_features_to_add = n_random_features_to_add\n",
    "        self.random_test_points_scale = random_test_points_scale\n",
    "        self.init_scale_factor = init_scale_factor\n",
    "        if store_intermediate_data:\n",
    "            self.loss_list = []\n",
    "            self.all_X_false_train = []\n",
    "\n",
    "\n",
    "    @staticmethod\n",
    "    def name() -> str:\n",
    "        return \"tabpfn_points\"\n",
    "\n",
    "    @staticmethod\n",
    "    def type() -> str:\n",
    "        return \"debug\"\n",
    "\n",
    "    @staticmethod\n",
    "    def hyperparameter_space(**kwargs: Any) -> List[Distribution]:\n",
    "        \"\"\"\n",
    "        We can customize the hyperparameter space, and use it in AutoML benchmarks.\n",
    "        \"\"\"\n",
    "        #TODO\n",
    "        return [\n",
    "            IntegerDistribution(name=\"embedding_n_units\", low=100, high=500, step=50),\n",
    "            IntegerDistribution(name=\"batch_size\", low=100, high=300, step=50),\n",
    "            IntegerDistribution(name=\"n_iter\", low=100, high=500, step=50),\n",
    "        ]\n",
    "\n",
    "    def _fit(self, X: DataLoader, X_false_train_init=None, *args: Any, **kwargs: Any) -> \"tabpfn_points_plugin\":\n",
    "        if X_false_train_init is None:\n",
    "            X_false_train = (np.random.rand(512, X.shape[1]) * 2 * self.random_test_points_scale - self.random_test_points_scale) / self.init_scale_factor\n",
    "        else:\n",
    "            X_false_train = X_false_train_init\n",
    "        self.X_false_train = torch.tensor(X_false_train).float().to(self.device)\n",
    "        self.X_false_train.requires_grad = True\n",
    "        X_true = self.preprocessor.fit_transform(X.numpy()) # all numerical features for now\n",
    "        X_true = torch.tensor(X_true, dtype=torch.float32).to(self.device)\n",
    "        X_random_test = np.random.rand(self.n_random_test_samples, X.shape[1]) * 2 * self.random_test_points_scale - self.random_test_points_scale\n",
    "        X_random_test = torch.tensor(X_random_test).float().to(self.device)\n",
    "\n",
    "        \n",
    "        optimizer = torch.optim.Adam([self.X_false_train], lr=self.lr)\n",
    "\n",
    "        tabpfn_classifier = TabPFNClassifier(device=self.device, N_ensemble_configurations=self.n_permutations,\n",
    "                                              no_preprocess_mode=True, no_grad=False, normalize=False)\n",
    "\n",
    "        for batch in tqdm(range(self.n_batches)):\n",
    "            n_train = 512\n",
    "            n_test = min(2048, X_true.shape[0])\n",
    "            tabpfn_output_proba_list = []\n",
    "            for _ in range(self.n_ensembles):\n",
    "                indices_train = np.random.choice(X_true.shape[0], n_train, replace=False)\n",
    "                X_batch_train = X_true[indices_train]\n",
    "                indices_test = np.random.choice(X_true.shape[0], n_test, replace=False)\n",
    "                X_batch_test = X_true[indices_test]\n",
    "                #indices_false_test = np.random.choice(X_random_test.shape[0], len(X_batch_test), replace=False)\n",
    "                #X_false_test = X_random_test[indices_false_test]\n",
    "                indices_false_test_from_random = np.random.choice(X_random_test.shape[0], len(X_batch_test) - self.n_test_from_false_train, replace=False)\n",
    "                X_false_test_from_random = X_random_test[indices_false_test_from_random]\n",
    "                indices_false_test_from_false_train = np.random.choice(self.X_false_train.shape[0], self.n_test_from_false_train, replace=False)\n",
    "                X_false_test_from_false_train = self.X_false_train.detach()[indices_false_test_from_false_train]\n",
    "                X_false_test = torch.cat((X_false_test_from_random, X_false_test_from_false_train), dim=0)\n",
    "\n",
    "                indices_false_train = np.random.choice(self.X_false_train.shape[0], len(X_batch_train), replace=False)\n",
    "                X_false_batch_train = self.X_false_train[indices_false_train]\n",
    "\n",
    "                X_train = torch.cat((X_batch_train, X_false_batch_train), dim=0)\n",
    "                X_test = torch.cat((X_batch_test, X_false_test), dim=0)\n",
    "                y_train = torch.cat((torch.ones(X_batch_train.shape[0]), torch.zeros(X_false_batch_train.shape[0])), dim=0).long()\n",
    "                y_test = torch.cat((torch.ones(X_batch_test.shape[0]), torch.zeros(X_false_test.shape[0])), dim=0).long()\n",
    "                #y_test = torch.ones(X_batch_test.shape[0]).long()\n",
    "                #y_test = torch.zeros(X_false_test.shape[0]).long()\n",
    "\n",
    "                perm_train = torch.randperm(X_train.shape[0])\n",
    "                X_train = X_train[perm_train]\n",
    "                y_train = y_train[perm_train]\n",
    "                perm_test = torch.randperm(X_test.shape[0])\n",
    "                X_test = X_test[perm_test]\n",
    "                y_test = y_test[perm_test]\n",
    "\n",
    "                # add a third feature to X_train and X_test with random values\n",
    "                if self.n_random_features_to_add > 0:\n",
    "                    X_train = torch.cat((X_train, torch.randn(X_train.shape[0], self.n_random_features_to_add).to(self.device)), dim=1)\n",
    "                    X_test = torch.cat((X_test, torch.randn(X_test.shape[0], self.n_random_features_to_add).to(self.device)), dim=1)\n",
    "                tabpfn_classifier.fit(X_train, y_train, overwrite_warning=True)\n",
    "                tabpfn_output_proba = tabpfn_classifier.predict_proba(X_test)\n",
    "                tabpfn_output_proba_list.append(tabpfn_output_proba)\n",
    "            tabpfn_output_proba = torch.stack(tabpfn_output_proba_list).mean(dim=0)\n",
    "\n",
    "            loss = torch.mean(torch.abs((tabpfn_output_proba[:, 0] - tabpfn_output_proba[:, 1]))**2)\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            if batch % 10 == 0:\n",
    "                print(f\"Batch {batch} loss: {loss.item()}\")\n",
    "\n",
    "            if self.store_intermediate_data:\n",
    "                self.loss_list.append(loss.item())\n",
    "                self.all_X_false_train.append(self.X_false_train.detach().cpu().numpy())\n",
    "    \n",
    "        return tabpfn_output_proba.detach().cpu(), self.X_false_train.detach().cpu(), y_test.detach().cpu()\n",
    "\n",
    "    def sample(self, count: int, **kwargs: Any) -> pd.DataFrame:\n",
    "        if count > len(self.X_false_train):\n",
    "            raise ValueError(\"Requested count exceeds the available data.\")\n",
    "        indices = np.random.choice(len(self.X_false_train), count, replace=False)\n",
    "        false_points = self.X_false_train[indices].detach().cpu().numpy()\n",
    "        return self.preprocessor.inverse_transform(false_points)\n",
    "    \n",
    "    def _generate(self, count: int, syn_schema: Schema, **kwargs: Any) -> pd.DataFrame:\n",
    "        return self._safe_generate(self.sample, count, syn_schema)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dpo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
